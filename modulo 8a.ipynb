{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql import Row\nfrom pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Cargamos el fichero u.data pero solo los campos que nos interesan: user, movie_id(product) y rating \ndata_file= sc.textFile('FileStore/tables/zpjo2tx51509035996987/u.data')\nratings = data_file.map(lambda l: l.split(\"\\t\")).map(lambda x:Rating(int(x[0]), int(x[1]), float(x[2])))\ntype(ratings)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["ratings.take(3)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Vamos a ver el total de usuarios unicos:\nratingdf = ratings.toDF() \nratingdf.select('user').distinct().show(5)\nratingdf.cache()\nratingdf.count()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["ratingdf.describe(\"rating\").show()  #El rango de los ratings es 1-5 y tenemos la media de ratings, que podriamos usar para rellenar los campos vacios"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["ratingdf.select('user').distinct().count() #total usuarios unicos."],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["ratingdf.groupBy(\"user\").count().take(5) #numero de productos recomendados por usuario"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["ratingdf.groupBy(\"rating\").count().show()  #numero de totales de cada puntuacion de rating."],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["ratingdf.stat.crosstab(\"user\", \"rating\").show() # resumen individual de ratings por usuario"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#Para construir un modelo lo más preciso posible dividimos los datos de entrada en conjuntos de datos de entrenamiento y prueba por separado\n#Para cada par (entrenamiento y prueba), itera a través del conjunto de parametros  y se ajustan al Estimador usandolos. De esta manera obtenemos el\n#modelo ajustado, y evaluamos  el rendimiento del modelo utilizando el Evaluador.\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml import Pipeline\npreds = cvModel.bestModel.transform(test)\n#lo primero es convertir el rating RDD en un dataframe\nratingsd=sqlContext.createDataFrame(ratings)\ntraining, test= ratingsd.randomSplit([0.8, 0.2])\ntraining.count()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["ratingdf.dropna().count()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#training.na.drop(how = 'any') #para evitar el resultado na en el cálculo del RMSE  \ntraining.cache()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["from pyspark.ml.recommendation import ALS\nals = ALS(userCol=\"user\", itemCol=\"product\",ratingCol=\"rating\", coldStartStrategy=\"drop\")"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["from pyspark.ml import Pipeline\npipeline = Pipeline(stages=[als])"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#Estalecemeos los diferentes parametros con los que el modelo ira probando hasta encontrar el mejor modelo.\nparamMap = ParamGridBuilder()   \\\n  .addGrid(als.rank, [4, 12])    \\\n  .addGrid(als.maxIter, [10, 30])     \\\n  .addGrid(als.regParam, [0.01, 0.1])    \\\n  .build()\n\nevaluatorR = RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\")\ncvExplicit = CrossValidator(estimator=als, estimatorParamMaps=paramMap, evaluator=evaluatorR,numFolds=5)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\nevaluatorR = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\")"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["#Entrenamos con el dataset training e incoporo comandos para ver el tiempo que tarda. He ido testeando diferentes parametros y combinanciones y he podido observar auqnue , reducir el RMSE ha sido a costa de incremento de tiempo.\nfrom time import time\nt0 = time()\ncvModel = cvExplicit.fit(training)\ntt = time() - t0\nprint \"model trained in %s seconds\" % round(tt,3)  #model trained in 271.262 seconds"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["#Evaluamos el modelo mirando el RMSE en los datos del test\npredict = cvModel.bestModel.transform(test)\nevaluator = RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["rmse = evaluator.evaluate(predict)\nprint 'For testing data the RMSE is %s' % (rmse)\n#For testing data the RMSE is 0.922383301033"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["#miramos el error en los datos del training. Al haber más datos, deberia tener un RMSE menor.\npredict = cvModel.bestModel.transform(training)\nrmse = evaluator.evaluate(preds)\nprint 'For training data the RMSE is %s' % (rmse)\n#For training data the RMSE is 0.0.819636022516-como vemos el error efectivamente ha disminuido"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["#Miro los diferentes parametros usados en el entrenamiento y sus respectivos RMSE de metrica.\nmetric_params_pairs = list(zip(cvModel.avgMetrics, cvModel.getEstimatorParamMaps()))\nmetric_params_pairs.sort(key=lambda x: x[0], reverse=True)\nbest_metric_params = metric_params_pairs[0][1]\nfor pair in metric_params_pairs:\n    metric, params = pair\n    print('metric', metric)\n    for k, v in params.items():\n        print(k.name, v)\n    print('')\n"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#Ya tenemos el modelo creado. Vamos a recuperar el archivo item para sacar el titulo de la pelicula y darle un poco más de forma.\n#Cargamos los datos de las peliculas archivados en el archivo u.item Cogeremos solo los datos de user_id y movie_title.\nitem_file= sc.textFile('FileStore/tables/zpjo2tx51509035996987/u.item')\nitemRDD = item_file.map(lambda l: l.split((\"|\")))\nmovies_titles= itemRDD.map(lambda p: (int(p[0]), p[1]))\nmovies = sqlContext.createDataFrame(movies_titles)\nmovies = movies.selectExpr(\"_1 as product\", \"_2 as title\")\nprint \"There are %s movies in the u.item file\" % (movies_titles.count()) #There are 1682 movies in the complete dataset\nmovies.cache()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#Volvemos a entrenar el modelo con el total del dataset.\npreds = cvModel.bestModel.transform(ratingsd)\n\n#unimos el dataframe preds con los titulos de las peliculas\npredstitle = preds.join(movies, preds.product == movies.product).selectExpr(\"user\",\"title\", \"rating\", \"prediction\")\ndisplay(predstitle)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#Recomendaciones de peliculas para un usuario concreto\nfrom pyspark.sql.functions import col\ndisplay(predstitle.where('user==3').sort(col(\"prediction\").desc()))"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["#Recomendacion a un usuario de las peliculas predecidas con prediccion superior a N(3)\ndisplay(predstitle.filter(\"user =='3' and prediction > 3\"))"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["#Ahora tenemos que puntuar peliculas para un nuevo usuario. Creamos un nuevo usuario \"0\" que no esta en el dataset inicial e incorporamos algunos ratings para el usuario. \nnew_user_id = 944\nnew_user_ratings = [\n  (944,1,4), #Toy Story\n  (944,11,5), #Seven\n  (944,50,4), #StarWars\n  (944,71,4), #The Lion King\n  (944,1569,4), #La vida es Bella\n  (944,362,3), #Blues Brothers\n  (944,288,2), #Scream \n  (944,301,3) #In & Out\n]\nnew_user_ratings_RDD = sc.parallelize(new_user_ratings)\nprint \"Ratings del nuevo usuario %s\" % new_user_ratings_RDD.take(8)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["#añadimos las recomendaciones del nuevo usuario con los ratings originales. Podemos unir los RDD o crear el dataframe del usuario y luego unir los DF.\nnew_userdf=new_user_ratings_RDD.toDF()\ncomplete_data_with_new_ratings_df = ratingdf.unionAll(new_userdf)\ncomplete_data_with_new_ratings_df.count()"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["#Con la incorporacion de cierto numero de nuevos usuarios, deberia volver a entrenarse el modelo y evaluarlo nuevamente para que la maquina aprenda con los nuevos datos del dataset."],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["training_new, test_new= complete_data_with_new_ratings_df.randomSplit([0.8, 0.2])\ntraining_new.cache()\ntest_new.cache()\nals = ALS(userCol=\"user\", itemCol=\"product\",ratingCol=\"rating\") \nevaluatorR = RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\")\ncvExplicit = CrossValidator(estimator=als, estimatorParamMaps=paramMap, evaluator=evaluatorR,numFolds=5)\ncvModel2 = cvExplicit.fit(training_new)\npredictions_new_user= cvModel2.bestModel.transform(test_new)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["#evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n#rmse = evaluator.evaluate(predictions)\n#print(\"RSME = \" + str(rmse)) "],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["display(predstitle.filter(\"user =='944' and prediction > 3\"))"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":37}],"metadata":{"name":"modulo 8a","notebookId":3984121285877547},"nbformat":4,"nbformat_minor":0}
